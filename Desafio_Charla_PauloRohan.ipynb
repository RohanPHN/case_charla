{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b9eaef5",
   "metadata": {},
   "source": [
    "# Desafio técnico Charla\n",
    "**Autor**: Paulo Rohan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa50003",
   "metadata": {},
   "source": [
    "Esse notebook contém a resolução do desafio técnico para a vaga de **Jr AI Engineer** da startup Charla.\n",
    "A descrição do desafio é a seguinte:\n",
    "\n",
    "\"Você deve criar um script em Python que utiliza a biblioteca PydanticAI para criar um agente de IA que extraia informações específicas de uma Nota Fiscal de Serviço (PDF) que forneceremos. O objetivo é ler o conteúdo do PDF, usar um LLM para “entender” o texto e retornar os dados de forma estruturada e validada.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2a7b86",
   "metadata": {},
   "source": [
    "### 1. Configuração do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c907072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os pacotes necessários\n",
    "\n",
    "## Manipulação de dados e arquivos\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import json\n",
    "\n",
    "## Anotação de erros e logging\n",
    "import logging\n",
    "\n",
    "## Definição de modelos e validação\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "## Construção do agente\n",
    "from pydantic_ai import Agent, BinaryContent\n",
    "from pydantic_ai.models.google import GoogleModel\n",
    "from pydantic_ai.providers.google import GoogleProvider\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "## Execução assíncrona\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369fd7b",
   "metadata": {},
   "source": [
    "### 2. Leitura do PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686f44b",
   "metadata": {},
   "source": [
    "Embora a tarefa pudesse ser realizada com apenas um único arquivo PDF refente a Nota Fiscal de Serviço, optei por utilizar dois arquivos. A minha escolha foi principalmente para tratar a tarefa de uma maneira mais escalável, construíndo a solução de forma que pudesse lidar com múltiplos arquivos. Dessa forma, busquei listar todos os arquivos PDF que estariam contidos dentro da pasta de armazenamento, utilizando a biblioteca `Path`, e em seguida obter o seu caminho, para que pudesse ser utilizado na abordagem de leitura com `BinaryContent`. Nessa etapa, apenas o caminho está sendo armazenado, com a leitura sendo feita posteriormente, no momento da execução da extração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb31705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos encontrados:\n",
      "\n",
      "dados\\nf_paulo_rohan.pdf\n",
      "dados\\nf_paulo_rohan_2.pdf\n"
     ]
    }
   ],
   "source": [
    "# Extraíndo os arquivos PDF contidos na pasta dados\n",
    "pasta_dados = Path('dados')\n",
    "\n",
    "# Armazenando os arquivos em uma lista\n",
    "lista_pdfs = [str(arquivo) for arquivo in pasta_dados.glob('*.pdf')]\n",
    "\n",
    "# Verificando os arquivos encontrados\n",
    "print(\"Arquivos encontrados:\\n\")\n",
    "for arquivo in lista_pdfs:\n",
    "    print(arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509d8cd",
   "metadata": {},
   "source": [
    "### 3. Modelagem dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c51ea2",
   "metadata": {},
   "source": [
    "O próximo passo foi utilizar a biblioteca `Pydantic` para representar a estrutura da informação que será extraída a partir da Nota Fiscal de Serviço. O `Pydantic`tem a função de definir modelos de dados com validação automática, garantindo que os dados extraídos sejam consistentes e estejam no formato correto. Os itens que devem ser extraídos são os seguintes:\n",
    "\n",
    "1. Descrição do Serviço\n",
    "2. Valor do serviço\n",
    "3. Número da Nota\n",
    "4. Data de emissão\n",
    "5. Valor total\n",
    "6. CNPJ do Prestador de Serviço\n",
    "\n",
    "Com base nisso, o tipo apropriado dos dados foi indicado na definição da estrutura para validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68dda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o Pydantic com o modelo da estrutura de extração\n",
    "class ExtracaoOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Define a estrutura de informação a ser extraída da nota fiscal.\n",
    "    \"\"\"\n",
    "    descricao_servico: str = Field(description=\"Descrição detalhada do serviço prestado.\")\n",
    "    valor_servico: float = Field(description=\"Valor referente ao item de serviço.\")\n",
    "    numero_nota: str = Field(description=\"Número identificador da nota fiscal.\")\n",
    "    data_emissao: date = Field(description=\"Data de emissão da nota fiscal.\")\n",
    "    valor_total: float = Field(description=\"Valor total líquido da nota fiscal.\")\n",
    "    cnpj_prestador: str = Field(description=\"CNPJ (Cadastro Nacional da Pessoa Jurídica) da empresa prestadora do serviço.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0710fe95",
   "metadata": {},
   "source": [
    "### 4. Extração de informações com pyndaticAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e0b2e",
   "metadata": {},
   "source": [
    "Finalmente, utilizando as credenciais fornecidas, o modelo Gemini 2.5 Flash foi instanciado para execução da tarefa. Com base nas credenciais, utilizei o Service Account para configurar o provedor e instanciar o modelo e o agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurando a service account através do JSON fornecido\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    'dados/charla-cuore-norma-278aadacc1b2.json',\n",
    "    scopes=['https://www.googleapis.com/auth/cloud-platform'],\n",
    ")\n",
    "\n",
    "# Instanciando o provider, modelo e agente\n",
    "provider = GoogleProvider(credentials=credentials, project='charla-cuore-norma')\n",
    "model = GoogleModel('gemini-2.5-flash', provider=provider)\n",
    "agent = Agent(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a693e9",
   "metadata": {},
   "source": [
    "Utilizando o agente instanciado, prossegui para a execução da extração das informações de interesse. Aqui, optei por utilizar o módulo assíncrono devido à sua eficiência no contexto de execução dentro de um Jupyter Notebook.\n",
    "\n",
    "O prompt utilizado seguiu o modelo \"task-specific\", iniciando com a descrição de uma persona e a tarefa a ser realizada. Esse tipo de prompt foi escolhido por sua capacidade de direcionar o modelo para uma tarefa específica, garantindo que a saída seja consistente e contenha apenas os campos de interesse. É importante ressaltar que esse prompt não é exaustivo e, em um ambiente real, poderia ser discutido com a equipe para torná-lo mais robusta e flexível a diferentes estruturas de arquivos.\n",
    "\n",
    "A lista de arquivos PDFs obtida na etapa 2 foi utilizada. Para cada arquivo, iterei sobre os caminhos na lista para executar a extração. Além disso, adicionei uma estrutura de logging para armazenar informações sobre a execução e possíveis erros, pensando em um cenário real, mesmo que erros não fossem esperados neste exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33172d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extrair_notas_fiscais(agent, lista_pdfs):\n",
    "    # Inicializando listas para armazenar resultados e erros\n",
    "    resultados = []\n",
    "    erros = []\n",
    "    \n",
    "    # Iterando sobre cada arquivo PDF na lista fornecida\n",
    "    for pdf_path in lista_pdfs:\n",
    "        try:\n",
    "            # Executando o agente para extrair informações estruturadas do PDF\n",
    "            resultado = await agent.run([\n",
    "                \"Você é um assistente especializado em extrair informações estruturadas de Notas Fiscais de Serviço em PDF. \"\n",
    "                \"Sua resposta deve ser exclusivamente um objeto JSON puro, sem formatação adicional, comentários ou explicações. \"\n",
    "                \"Certifique-se de que a saída siga rigorosamente o modelo ExtracaoOutput e contenha os campos:\"\n",
    "                \"descricao_servico, valor_servico, numero_nota, data_emissao, valor_total, cnpj_prestador.\",\n",
    "                \n",
    "                # Indicando o conteúdo para leitura\n",
    "                BinaryContent(data=Path(pdf_path).read_bytes(), media_type=\"application/pdf\"),\n",
    "                \n",
    "                # Indicando a estrutura de saída esperada\n",
    "                \"ExtracaoOutput\"\n",
    "            ])\n",
    "            # Adicionando o resultado à lista de resultados\n",
    "            resultados.append({'arquivo': pdf_path, 'output': resultado.output})\n",
    "            logging.info(f'Sucesso: {pdf_path}')\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Registrando possíveis erros\n",
    "            erros.append({'arquivo': pdf_path, 'erro': str(e)})\n",
    "            logging.error(f'Erro em {pdf_path}: {e}')\n",
    "    \n",
    "    # Retornando os resultados e erros\n",
    "    return resultados, erros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356d3ab",
   "metadata": {},
   "source": [
    "### 5. Output\n",
    "\n",
    "Após a execução da extração, os resultados obtidos precisaram ser tratados para garantir que estivessem no formato correto de JSON. Embora o prompt tenha sido ajustado para solicitar uma saída consistente, o modelo pode retornar respostas com variações, como delimitadores de bloco de código ou formatações adicionais. \n",
    "\n",
    "Para lidar com essas inconsistências, foi necessário implementar uma etapa de pós-processamento para remover possiveis elementos indesejados e garantir que o JSON seja válido e utilizável. \n",
    "\n",
    "Acredito que em um ambiente de produção, o pós-processamento seria uma etapa crítica para assegurar que os dados estejam no formato esperado, independentemente de variações na saída do modelo. Além disso, essa abordagem permite maior flexibilidade para lidar com diferentes tipos de entradas e possíveis ajustes futuros no comportamento do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d86f7a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saídas dos resultados:\n",
      "\n",
      "Arquivo: dados\\nf_paulo_rohan.pdf\n",
      "\n",
      "{\n",
      "    \"descricao_servico\": \"CAP AXXIS AB METRO S SOLID A2 TIT\",\n",
      "    \"valor_servico\": 479.99,\n",
      "    \"numero_nota\": \"000006950\",\n",
      "    \"data_emissao\": \"27/02/2025\",\n",
      "    \"valor_total\": 479.99,\n",
      "    \"cnpj_prestador\": \"22113749000188\"\n",
      "}\n",
      "\n",
      "Arquivo: dados\\nf_paulo_rohan_2.pdf\n",
      "\n",
      "{\n",
      "    \"descricao_servico\": \"C.JNS RETA ESP ESCURA BLACK 44\",\n",
      "    \"valor_servico\": \"199,90\",\n",
      "    \"numero_nota\": \"000327907\",\n",
      "    \"data_emissao\": \"25/02/2024\",\n",
      "    \"valor_total\": \"199,90\",\n",
      "    \"cnpj_prestador\": \"02.737.654/0008-02\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extraindo os resultados\n",
    "resultados, erros = await extrair_notas_fiscais(agent, lista_pdfs)\n",
    "\n",
    "# Iniciando a lista para armazenar os resultados pós-processados\n",
    "resultados_tratados = []\n",
    "\n",
    "# Exibindo a saída para cada arquivo, em formato JSON\n",
    "print(\"Saídas dos resultados:\\n\")\n",
    "for res in resultados:\n",
    "    try:\n",
    "        # Se necessário, convertendo o campo 'output' de string para JSON\n",
    "        output_json = json.loads(res['output'].strip('```json').strip())\n",
    "\n",
    "        # Adicionando o resultado diretamente à lista de resultados tratados\n",
    "        resultados_tratados.append({\"arquivo\": res['arquivo'], \"output\": output_json})\n",
    "\n",
    "        # Exibindo o nome do arquivo seguido pelo JSON\n",
    "        print(f\"Arquivo: {res['arquivo']}\\n\")\n",
    "        print(json.dumps(output_json, indent=4, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        # Caso o campo 'output' não seja um JSON válido, registrar o erro\n",
    "        logging.error(f\"Erro ao processar o arquivo: {res['arquivo']}\")\n",
    "        print(f\"Arquivo: {res['arquivo']}\")\n",
    "        print(json.dumps(res['output'], indent=4, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-case-charla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
